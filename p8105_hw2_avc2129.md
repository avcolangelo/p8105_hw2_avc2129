Homework 2
================
Alexis Colangelo
10/3/2019

``` r
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(dplyr)
```

## Problem 1: Mr. Trash Wheel

### Read and clean Mr. Trash Wheel sheet

  - Specify the sheet in the Excel file and to omit non-data entries
    (rows with notes / figures; columns containing notes) using
    arguments in read\_excel.\`
  - Use reasonable variable names
  - Omit rows that do not include dumpster-specific data
  - Round the number of sports balls to the nearest integer and convert
    the result to an integer variable (using as.integer)

<!-- end list -->

``` r
trash_data =
  read_excel("./data/mr_trash_wheel.xlsx", sheet = 1, range = "A2:N408") %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(sports_balls = round(sports_balls, digits = 0)) %>%
  mutate(sports_balls = as.integer(sports_balls))
```

### Read and clean precipitation data for 2017 and 2018.

  - For each, omit rows without precipitation data and add a variable
    year.

<!-- end list -->

``` r
precip_17 = 
  read_excel("./data/mr_trash_wheel.xlsx", sheet = 6, range = "A2:B14") %>%
  janitor::clean_names() %>%
  mutate(year = 2017)
```

``` r
precip_18 = 
  read_excel("./data/mr_trash_wheel.xlsx", sheet = 5, range = "A2:B14") %>%
  janitor::clean_names() %>%
  mutate(year = 2018)
```

  - Combine precipitation datasets and convert month to a character
    variable (the variable month.name is built into R and should be
    useful).

<!-- end list -->

``` r
precip_data =
  full_join(precip_17, precip_18, by = c("month", "year", "total")) %>%
  arrange(month) %>%
  mutate(month = month.name[month])
```

### Write a paragraph about these data; you are encouraged to use inline R.

  - Be sure to note the number of observations in both resulting
    datasets, and give examples of key variables.
  - For available data, what was the total precipitation in 2018?
  - What was the median number of sports balls in a dumpster in 2017?

In the Mr. Trash Wheel data set, there are 344 observations and 14
columns or variables for each observation. An example of a key variable
includes the weight of trash removed, which totals 1122.45 tons from May
2014 to June 2019. Another key variable is homes powered, which the
average dumpster powered 43.8250969 homes in the same time frame. The
median number of sports balls in a dumpster in 2017 was 8.

In the precipitation data set, there are 24 observations and 3 columns
or variables for each observation. An example of a key variable is total
precipitation, which averaged 2.7441667 in 2017. An example of another
key variable is month, the average precipitation in July for 2017 and
2018 was 8.645. The total precipitation in 2018 was 70.33.

## Problem 2: 538

### Clean the data in pols-month.csv.

  - Use separate() to break up the variable mon into integer variables
    year, month, and day
  - Replace month number with month name
  - Create a president variable taking values gop and dem, and remove
    prez\_dem and prez\_gop;
  - remove the day variable.

<!-- end list -->

``` r
pols_data =
  read_csv(file = "./data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day")) %>%
  mutate(month = as.integer(month)) %>%
  mutate(month = month.name[month]) %>%
  mutate(prez_gop = as.character(prez_gop)) %>%
  mutate(prez_gop = recode(prez_gop, "1" = "gop", "0" = "dem")) %>%
  mutate(prez_dem = as.character(prez_dem)) %>%
  mutate(prez_dem = recode(prez_dem, "1" = "dem", "0" = "gop")) %>%
  mutate(prez = prez_gop) %>%
  select(-prez_gop, -prez_dem, -day)
```

### Clean the data in snp.csv

  - Clean the data in snp.csv using a similar process to the above
  - For consistency across datasets, arrange according to year and
    month, and organize so that year and month are the leading columns.

<!-- end list -->

``` r
snp_data =
  read_csv(file = "./data/fivethirtyeight_datasets/snp.csv") %>%
  separate(date, into = c("month", "day", "year")) %>%
  mutate(month = as.integer(month)) %>%
  mutate(month = month.name[month]) %>%
  arrange(year, month) %>%
  select(year, month, close, -day)
```

### Tidy the unemployment data so that it can be merged with the previous datasets.

  - This process will involve switching from “wide” to “long” format;
    ensuring that key variables have the same name; and ensuring that
    key variables take the same values.

<!-- end list -->

``` r
unemploy_data =
   read_csv(file = "./data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemploy_percent") %>%
  mutate(month = recode(month, "jan" = "January", "feb" = "February", "mar" = "March", "apr" = "April", "may" = "May", "jun" = "June", "jul" = "July", "aug" = "August", "sep" = "September", "oct" = "October", "nov" = "November", "dec" = "December"))
```

### Join the datasets by merging snp into pols, and merging unemployment into the result.

``` r
fte_data =
  left_join(pols_data, snp_data, by = c("month","year")) %>%
  mutate(year = as.numeric(year)) %>%
  left_join(unemploy_data, by = c("month", "year"))
```

### Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).

The first dataset (pols\_data) contained information from January 1947
to June 2015 on which political party held the presidency, and the
number and political party of senators, governors, and representatives
at that particular time. Pols\_data contained 822 total observations and
9 columns/variables. The second dataset (snp\_data) included S\&P stock
index values at close from April 1950 to May 2015. Snp\_data contained
787 total observations and 3 columns/variables. Months and years were
included in the dataset. The third dataset (unemploy\_data) contained
unemployment rates in percents for each month and year observed ranging
from January 1948 to June 2015 (July to December 2015 rates were NA in
the dataset). Unemploy\_data contained 816 total observations and 3
columns/variables.

The resulting dataset (fte\_data) containing the three datasets
mentioned above contained information ranging from January 1947 to June
2015. It included 822 total observations and 11 columns/variables. Some
key variables in the total dataset include the political party of the
sitting president, stock index value at close, the percent of
unemployment, months, and years.

## Problem 3: Baby Names

### Load and tidy the data.

  - Although these data may seem fairly well formatted initially, the
    names of a categorical predictor and the case structure of string
    variables changed over time; you’ll need to address this in your
    data cleaning.

  - Also, some rows seem duplicated, and these will need to be removed
    (hint: google something like “dplyr remove duplicate rows” to get
    started).

<!-- end list -->

``` r
name_data =
  read_csv(file = "./data/popular_baby_names.csv") %>%
janitor::clean_names() %>%
  distinct() %>%
  mutate(gender = str_to_lower(gender)) %>%
  mutate(ethnicity = str_to_lower(ethnicity)) %>%
  mutate(childs_first_name = str_to_lower(childs_first_name)) %>%
  mutate(ethnicity = recode(ethnicity, `asian and pacific islander` = "asian_pac_isl", `asian and paci` = "asian_pac_isl", `black non hispanic` = "black_nonhisp", `black non hisp` = "black_nonhisp", `white non hispanic` = "white_nonhisp", `white non hisp` = "white_nonhisp"))
```
